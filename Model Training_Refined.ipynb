{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7d1fe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99315814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the two cleaned datasets\n",
    "linear_df = pd.read_csv(\"Engineered/train_linear_ready.csv\")\n",
    "xgb_df = pd.read_csv(\"Engineered/train_xgb_ready.csv\")\n",
    "\n",
    "# Split: Features and target\n",
    "X1 = linear_df.drop(columns=\"SalePrice\")\n",
    "y1 = linear_df[\"SalePrice\"]\n",
    "\n",
    "X2 = xgb_df.drop(columns=\"SalePrice\")\n",
    "y2 = xgb_df[\"SalePrice\"]\n",
    "\n",
    "# Train-test split (80% train, 20% test) for both (controlled random_state)\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fa1e551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 965\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 181441.541952\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000245 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1075\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 181441.541952\n",
      "              Model FeatureSet    Train_RMSE     Test_RMSE  Train_R2   Test_R2\n",
      "0  LinearRegression         X1  36942.399110  38556.853438  0.771191  0.806184\n",
      "1  LinearRegression         X2  37774.633877  39358.543250  0.760766  0.798041\n",
      "2      XGBRegressor         X1  10385.202550  30136.292008  0.981918  0.881596\n",
      "3      XGBRegressor         X2  12519.543123  30209.856934  0.973722  0.881017\n",
      "4     LGBMRegressor         X1  16921.106492  32734.405046  0.951996  0.860300\n",
      "5     LGBMRegressor         X2  19015.641015  31983.037424  0.939376  0.866640\n"
     ]
    }
   ],
   "source": [
    "# Initialize models\n",
    "lr_model = LinearRegression()\n",
    "xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "lgbm_model = LGBMRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "# n_estimators=100     Number of boosting rounds (i.e., how many trees are built)\n",
    "# learning_rate=0.1    Shrinks the contribution of each tree; lower = slower learning but more stable\n",
    "# random_state=42      Ensures reproducibility (same random splits and results each run)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(name, model, X_train, y_train, X_test, y_test,feature_set):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    return {\n",
    "        \"Model\": name,\n",
    "        \"FeatureSet\": feature_set,\n",
    "        \"Train_RMSE\": np.sqrt(mean_squared_error(y_train, y_train_pred)),\n",
    "        \"Test_RMSE\": np.sqrt(mean_squared_error(y_test, y_test_pred)),\n",
    "        \"Train_R2\": r2_score(y_train, y_train_pred),\n",
    "        \"Test_R2\": r2_score(y_test, y_test_pred)\n",
    "    }\n",
    "\n",
    "\n",
    "# Train & collect results\n",
    "results = []\n",
    "\n",
    "# LinearRegression on X1 and X2\n",
    "results.append(evaluate(\"LinearRegression\", lr_model, X1_train, y1_train, X1_test, y1_test,\"X1\"))\n",
    "results.append(evaluate(\"LinearRegression\", lr_model, X2_train, y2_train, X2_test, y2_test,\"X2\"))\n",
    "\n",
    "# XGBRegressor on X1 and X2\n",
    "results.append(evaluate(\"XGBRegressor\", xgb_model, X1_train, y1_train, X1_test, y1_test,\"X1\"))\n",
    "results.append(evaluate(\"XGBRegressor\", xgb_model, X2_train, y2_train, X2_test, y2_test,\"X2\"))\n",
    "\n",
    "# LGBMRegressor on X1 and X2\n",
    "results.append(evaluate(\"LGBMRegressor\", lgbm_model, X1_train, y1_train, X1_test, y1_test,\"X1\"))\n",
    "results.append(evaluate(\"LGBMRegressor\", lgbm_model, X2_train, y2_train, X2_test, y2_test,\"X2\"))\n",
    "\n",
    "# Step 7: Summary table\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8106b2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 965\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 181441.541952\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000136 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 957\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 179651.292808\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000128 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 950\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 181104.263699\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000107 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 958\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 181327.004281\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000123 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 960\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 181081.876712\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000114 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 965\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 181441.541952\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000122 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 957\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 179651.292808\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 950\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 181104.263699\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 958\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 181327.004281\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000128 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 960\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 181081.876712\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000249 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1075\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 181441.541952\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000269 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1068\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 179651.292808\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000193 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1060\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 181104.263699\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1072\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 181327.004281\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000204 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1073\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 181081.876712\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1075\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 181441.541952\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000212 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1068\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 179651.292808\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1060\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 181104.263699\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000323 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1072\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 181327.004281\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000188 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1073\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 181081.876712\n",
      "              Model FeatureSet    Train_RMSE     Test_RMSE       CV_RMSE  \\\n",
      "0  LinearRegression         X1  36942.399110  38556.853438  38398.666116   \n",
      "1  LinearRegression         X2  37774.633877  39358.543250  39219.975899   \n",
      "2      XGBRegressor         X1  10385.202550  30136.292008  31859.470313   \n",
      "3      XGBRegressor         X2  12519.543123  30209.856934  32368.469922   \n",
      "4     LGBMRegressor         X1  16921.106492  32734.405046  32288.198194   \n",
      "5     LGBMRegressor         X2  19015.641015  31983.037424  33210.593115   \n",
      "\n",
      "   Train_R2   Test_R2     CV_R2  \n",
      "0  0.771191  0.806184  0.748398  \n",
      "1  0.760766  0.798041  0.738065  \n",
      "2  0.981918  0.881596  0.830401  \n",
      "3  0.973722  0.881017  0.825862  \n",
      "4  0.951996  0.860300  0.824002  \n",
      "5  0.939376  0.866640  0.814906  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "# Define 5-fold cross-validation object\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize CV result columns\n",
    "results_df[\"CV_RMSE\"] = None\n",
    "results_df[\"CV_R2\"] = None\n",
    "\n",
    "# Map string name to actual model (each re-instantiated)\n",
    "model_map = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"XGBRegressor\": XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42),\n",
    "    \"LGBMRegressor\": LGBMRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "}\n",
    "\n",
    "# Loop over each row and compute CV metrics\n",
    "for i, row in results_df.iterrows():\n",
    "    model_name = row[\"Model\"]\n",
    "    feature_set = row[\"FeatureSet\"]\n",
    "    \n",
    "    # Pick correct features and target\n",
    "    X = X1 if feature_set == \"X1\" else X2\n",
    "    y = y1 if feature_set == \"X1\" else y2\n",
    "    \n",
    "    # Reinitialize model to prevent data leakage\n",
    "    model = model_map[model_name]\n",
    "    \n",
    "    # Cross-validation RÂ² scores (use scoring='r2')\n",
    "    cv_r2_scores = cross_val_score(model, X, y, cv=kf, scoring='r2')\n",
    "    cv_rmse_scores = -cross_val_score(model, X, y, cv=kf, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "    # Store mean results\n",
    "    results_df.at[i, \"CV_R2\"] = cv_r2_scores.mean()\n",
    "    results_df.at[i, \"CV_RMSE\"] = cv_rmse_scores.mean()\n",
    "\n",
    "# Reorder columns for your layout preference\n",
    "results_df = results_df[[\n",
    "    \"Model\", \"FeatureSet\", \n",
    "    \"Train_RMSE\", \"Test_RMSE\", \"CV_RMSE\",\n",
    "    \"Train_R2\", \"Test_R2\", \"CV_R2\"\n",
    "]]\n",
    "\n",
    "# Show table\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7374f2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save full evaluation results to CSV\n",
    "results_df.to_csv(\"Model_Evaluation_Results.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
